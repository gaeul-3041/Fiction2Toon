{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AW8Dav1DJHpd"
   },
   "source": [
    "### 모델 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4183,
     "status": "ok",
     "timestamp": 1738542213834,
     "user": {
      "displayName": "이상화",
      "userId": "16591940094992373463"
     },
     "user_tz": -540
    },
    "id": "D-k21oA_Lgc_",
    "outputId": "0f556e75-6f67-45fb-bb05-73b7a0475acd"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24388,
     "status": "ok",
     "timestamp": 1738542245449,
     "user": {
      "displayName": "이상화",
      "userId": "16591940094992373463"
     },
     "user_tz": -540
    },
    "id": "axjwYzNj52BN",
    "outputId": "210d8a73-2ce3-49b6-c85c-844409efa888"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Colab users)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVSoYn-xOKrw"
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration, Trainer, TrainingArguments, get_scheduler\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 파일 업로드\n",
    "file_path = \"/content/drive/MyDrive/Colab Notebooks/시나리오 변환 NLP/action.csv\"  # 파일 경로 수정 필요\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "train_data = data  \n",
    "\n",
    "# caption, act 열만 사용\n",
    "def prepare_data(data):\n",
    "    return Dataset.from_pandas(data[['caption', 'act']])\n",
    "\n",
    "train_dataset = prepare_data(train_data)\n",
    "\n",
    "# 모델 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"digit82/kobart-summarization\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"digit82/kobart-summarization\")\n",
    "\n",
    "# 토큰 데이터\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['caption'],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples['act'],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    ).input_ids\n",
    "    model_inputs['labels'] = labels\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./kobart_results\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./kobart_logs',\n",
    "    logging_steps=50,\n",
    "    warmup_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# 옵티마이저 조절\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "num_training_steps = len(train_dataset) * training_args.num_train_epochs // training_args.per_device_train_batch_size\n",
    "scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=training_args.warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 트레인 정의\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model(\"/content/drive/MyDrive/Colab Notebooks/시나리오 변환 NLP/prompt_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14137,
     "status": "ok",
     "timestamp": 1738543583974,
     "user": {
      "displayName": "이상화",
      "userId": "16591940094992373463"
     },
     "user_tz": -540
    },
    "id": "lFQYRrVTPL8C",
    "outputId": "f2af37a0-3ee9-426d-c69b-8060587ef4f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트를 입력하세요: 윤은 누군가 자신을 따라오고 있다는 것을 느끼며, 그 상대가 얼마 전 만났던 여대생임을 깨닫는다. 그는 그녀가 하룻밤 상대였지만, 그녀가 다음 날부터 여자친구처럼 행동하려는 모습에 당황한다.\n",
      "결과:\n",
      "{\n",
      "    \"output\": \"윤은 누군가 자신을 따라오고 있다는 것을 느끼며, 그 상대가 얼마 전 만났던 여대생임을 깨닫는다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_path = \"/content/drive/MyDrive/Colab Notebooks/시나리오 변환 NLP/prompt_model\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "def process_input():\n",
    "    \"\"\"\n",
    "    사용자 입력을 받아서 처리하고 결과를 출력\n",
    "    \"\"\"\n",
    "    text = input(\"텍스트를 입력하세요: \")\n",
    "\n",
    "    # 모델 입력 생성\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    # 모델 출력 생성\n",
    "    output_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=512,\n",
    "        num_beams=4,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    # 디코딩\n",
    "    generated_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # JSON 형식으로 출력\n",
    "    print(\"결과:\")\n",
    "    print(json.dumps({\"output\": generated_output}, indent=4, ensure_ascii=False))\n",
    "\n",
    "# 실행\n",
    "process_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDee7H2rCODI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
